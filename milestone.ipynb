{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c13d3df4-841f-44fc-9a78-940aa31c9a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, DataCollatorWithPadding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c652afd-142b-498f-9eb2-2e78e37ac5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5981a74-7291-4d1d-9384-d359495b9820",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce329826-2b6f-4273-b2e2-0fadcd47c40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02763ae4-715a-4ea5-95a4-08da87e91a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2665ca99-3b79-4043-85a5-c32aa8b5d44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sst2 = load_dataset(\"stanfordnlp/sst2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05f17e9d-87e2-45f2-8822-4221fb7ba594",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['idx', 'sentence', 'label'],\n",
       "    num_rows: 67349\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sst2[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f07a109-c845-499c-8a37-944674bd57dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['idx', 'sentence', 'label'],\n",
       "    num_rows: 872\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sst2[\"validation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72343472-ba18-4bf5-b73a-41d48cc602cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['idx', 'sentence', 'label'],\n",
       "    num_rows: 1821\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sst2[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac07d8c-a261-4c40-890f-0f99a776d993",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8296f9b-3e2b-4b60-b39c-9109ecc7ca01",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"google/mobilebert-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54a1bcf1-14d2-44cc-afb6-a6a029744da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(batch: Dict[str, List]):\n",
    "    return tokenizer(batch[\"sentence\"], truncation=True, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84bf1317-4b72-4cd3-9ad7-b3bddd20393e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62031c7e78c9450a99e2bbb9df1967a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_sst2 = sst2.map(tokenize, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cd4fb1-12c0-4b37-87f6-5da21cc09022",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5bbde77b-f436-48fd-8132-8ff947f33b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "907c634b-fe41-4bba-8774-781618023f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fada22b0-b826-4720-9a94-de697da9aa51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_prediction):\n",
    "    predictions, labels = eval_prediction\n",
    "    return accuracy.compute(\n",
    "        predictions=np.argmax(predictions, axis=1),\n",
    "        references=labels,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e544ab6c-77cc-4c26-a2e9-25be47374d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8dbff19c-5f19-4db5-b4c2-f01a132eaf3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MobileBertForSequenceClassification were not initialized from the model checkpoint at google/mobilebert-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"google/mobilebert-uncased\",\n",
    "    num_labels=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a6c5159e-b289-4f20-9674-449317135a7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MobileBertForSequenceClassification(\n",
       "  (mobilebert): MobileBertModel(\n",
       "    (embeddings): MobileBertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 128, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 512)\n",
       "      (token_type_embeddings): Embedding(2, 512)\n",
       "      (embedding_transformation): Linear(in_features=384, out_features=512, bias=True)\n",
       "      (LayerNorm): NoNorm()\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (encoder): MobileBertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-23): 24 x MobileBertLayer(\n",
       "          (attention): MobileBertAttention(\n",
       "            (self): MobileBertSelfAttention(\n",
       "              (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): MobileBertSelfOutput(\n",
       "              (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (LayerNorm): NoNorm()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): MobileBertIntermediate(\n",
       "            (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "            (intermediate_act_fn): ReLU()\n",
       "          )\n",
       "          (output): MobileBertOutput(\n",
       "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "            (bottleneck): OutputBottleneck(\n",
       "              (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (LayerNorm): NoNorm()\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (bottleneck): Bottleneck(\n",
       "            (input): BottleneckLayer(\n",
       "              (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (LayerNorm): NoNorm()\n",
       "            )\n",
       "            (attention): BottleneckLayer(\n",
       "              (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (LayerNorm): NoNorm()\n",
       "            )\n",
       "          )\n",
       "          (ffn): ModuleList(\n",
       "            (0-2): 3 x FFNLayer(\n",
       "              (intermediate): MobileBertIntermediate(\n",
       "                (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "                (intermediate_act_fn): ReLU()\n",
       "              )\n",
       "              (output): FFNOutput(\n",
       "                (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "                (LayerNorm): NoNorm()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): MobileBertPooler()\n",
       "  )\n",
       "  (dropout): Dropout(p=0.0, inplace=False)\n",
       "  (classifier): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736479ad-117b-47dd-ad9a-4832ef5895d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9db473a4-b09f-40b8-ab6f-ae3fbcaf64d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps', index=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model.to(\"mps\")\n",
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4f3f86-98ff-4893-825b-d96d33a0aacb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "99304742-fadb-447c-90b7-d464cb2aaeae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21050' max='21050' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21050/21050 2:31:17, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.194800</td>\n",
       "      <td>0.279231</td>\n",
       "      <td>0.917431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.157700</td>\n",
       "      <td>0.367442</td>\n",
       "      <td>0.909404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.112100</td>\n",
       "      <td>0.348334</td>\n",
       "      <td>0.922018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.103300</td>\n",
       "      <td>0.399022</td>\n",
       "      <td>0.916284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.074600</td>\n",
       "      <td>0.477361</td>\n",
       "      <td>0.909404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=21050, training_loss=898.4853809164256, metrics={'train_runtime': 9077.9515, 'train_samples_per_second': 37.095, 'train_steps_per_second': 2.319, 'total_flos': 1452184699411620.0, 'train_loss': 898.4853809164256, 'epoch': 5.0})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"tmp/mobilebert\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    push_to_hub=False,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_sst2[\"train\"],\n",
    "    eval_dataset=tokenized_sst2[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82cab80-2157-473e-a630-1d7af548c07a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "29894702-a242-4172-95e0-46e749017d4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MobileBertForSequenceClassification(\n",
       "  (mobilebert): MobileBertModel(\n",
       "    (embeddings): MobileBertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 128, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 512)\n",
       "      (token_type_embeddings): Embedding(2, 512)\n",
       "      (embedding_transformation): Linear(in_features=384, out_features=512, bias=True)\n",
       "      (LayerNorm): NoNorm()\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (encoder): MobileBertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-23): 24 x MobileBertLayer(\n",
       "          (attention): MobileBertAttention(\n",
       "            (self): MobileBertSelfAttention(\n",
       "              (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): MobileBertSelfOutput(\n",
       "              (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (LayerNorm): NoNorm()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): MobileBertIntermediate(\n",
       "            (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "            (intermediate_act_fn): ReLU()\n",
       "          )\n",
       "          (output): MobileBertOutput(\n",
       "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "            (bottleneck): OutputBottleneck(\n",
       "              (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (LayerNorm): NoNorm()\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (bottleneck): Bottleneck(\n",
       "            (input): BottleneckLayer(\n",
       "              (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (LayerNorm): NoNorm()\n",
       "            )\n",
       "            (attention): BottleneckLayer(\n",
       "              (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (LayerNorm): NoNorm()\n",
       "            )\n",
       "          )\n",
       "          (ffn): ModuleList(\n",
       "            (0-2): 3 x FFNLayer(\n",
       "              (intermediate): MobileBertIntermediate(\n",
       "                (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "                (intermediate_act_fn): ReLU()\n",
       "              )\n",
       "              (output): FFNOutput(\n",
       "                (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "                (LayerNorm): NoNorm()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): MobileBertPooler()\n",
       "  )\n",
       "  (dropout): Dropout(p=0.0, inplace=False)\n",
       "  (classifier): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d647c1e9-3886-4798-9dff-671d2a124e6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.2266, -0.0468, -0.1313,  ..., -0.0694,  0.1024,  0.0643],\n",
       "         [ 0.2212, -0.1479,  0.0529,  ...,  0.1253, -0.0353, -0.0575],\n",
       "         [ 0.0316, -0.0239,  0.1146,  ..., -0.0174, -0.0099,  0.0407],\n",
       "         ...,\n",
       "         [ 0.0746,  0.1113,  0.1695,  ...,  0.1416,  0.0800,  0.0718],\n",
       "         [-0.1779, -0.0636, -0.2137,  ...,  0.0496, -0.0058,  0.1994],\n",
       "         [ 0.1006,  0.0032,  0.1494,  ..., -0.0088,  0.1172, -0.1506]],\n",
       "        device='mps:0', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 9.9882e-02, -2.1004e-01, -7.4925e-01, -3.6873e-01,  1.5776e-01,\n",
       "         -1.2681e-01, -1.4546e-01, -3.0952e-02, -3.1803e-01,  1.3049e-01,\n",
       "          2.8325e-01,  1.2784e-01,  1.0947e-01,  8.4597e-03,  1.9864e-01,\n",
       "          1.9554e-01, -1.0397e-01,  8.0338e-02,  2.3664e+00,  4.5677e-02,\n",
       "         -1.5654e-01, -2.9233e-01, -2.4647e-01, -4.6836e-01, -7.0618e-02,\n",
       "          1.2230e-02,  2.3433e-01, -1.3977e-03,  8.0074e-02,  2.1029e-01,\n",
       "          3.6164e-02,  8.2796e-02,  4.9146e-01, -2.5112e-01,  5.1770e-01,\n",
       "          5.7232e-01,  3.3438e-01,  6.6916e-01, -1.2785e-01, -6.3470e-01,\n",
       "         -2.3442e-01,  5.5058e-01, -2.5212e-01,  3.7461e-01,  1.4275e-01,\n",
       "         -9.5278e-01,  3.8836e-01, -3.2073e-01,  5.9206e-01,  3.4458e-01,\n",
       "          1.5138e-01, -2.6958e-02, -6.7429e-01,  6.5559e-01, -6.1405e-01,\n",
       "          2.5588e-01, -4.5786e-01,  1.6474e-02, -1.1962e+00,  5.2803e-01,\n",
       "          3.3109e-01, -3.5064e-01, -1.6358e+00, -1.1176e-01, -3.4698e-01,\n",
       "          3.7428e-01,  1.1279e-01, -1.1966e-01,  1.7518e-01,  6.5273e-01,\n",
       "          3.0779e-01,  2.4830e-01, -3.4957e-01,  2.9021e-01,  1.3185e+00,\n",
       "         -6.7980e-01, -1.1004e+00,  3.5910e-01, -3.0526e-01,  4.4283e-01,\n",
       "          4.0174e-01,  8.8769e-01,  9.2640e-01, -1.2785e-01,  3.0202e-01,\n",
       "          4.4481e-01,  4.3210e-01, -2.2669e-01,  1.3822e-01, -4.4476e-01,\n",
       "         -1.6490e-01,  7.1229e-01,  5.0867e-01, -2.5067e-01, -5.4311e-01,\n",
       "         -1.0362e+00, -1.9257e-01,  1.9131e-01, -2.8296e-01,  2.0074e+00,\n",
       "          1.3732e+00, -1.7737e-01,  2.4599e-01, -1.3968e+00, -5.8196e-03,\n",
       "         -2.1223e-01, -1.7414e-01, -8.3920e-02,  5.1115e-03,  9.6068e-02,\n",
       "          2.6836e-01,  3.8873e-01,  1.8570e-01,  3.1810e-01,  6.9050e-02,\n",
       "          2.9153e-01,  2.1814e-01, -7.4151e-02,  5.1921e-02,  1.6619e-01,\n",
       "         -2.9437e-01, -1.4297e-01, -1.1775e+00, -3.1229e-01, -2.9727e-01,\n",
       "          2.6863e-01,  1.6881e-01,  1.2573e-01], device='mps:0',\n",
       "        requires_grad=True)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.mobilebert.encoder.layer[0].attention.self.query.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c49d83b1-983e-41ea-842b-64882649ae18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24582914"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([param.numel() for param in model.parameters() if param.requires_grad])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b4c11468-7e46-43c4-ac44-81306bc5010d",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985149fd-cd01-44ed-8a7c-ea1b0bba646f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5285946-af2f-4814-8e93-ff8280ce945a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a3efbb-5269-46c5-aca2-8580e8e3d8d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3a41a7e5-cfd9-4965-907f-e62cb4c39a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoRAUpdate(nn.Module):\n",
    "    def __init__(self, in_features, out_features, rank, alpha, device=None):\n",
    "        super().__init__()\n",
    "        self.A = nn.Parameter(data=torch.empty((in_features, rank), device=device))\n",
    "        with torch.no_grad():\n",
    "            nn.init.xavier_normal_(self.A)\n",
    "        self.B = nn.Parameter(data=torch.zeros((rank, out_features), device=device))\n",
    "        self.rank = rank\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def forward(self, input):\n",
    "        return (input @ self.A @ self.B) * self.alpha / self.rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a1cac2c7-ac7b-4135-9d0f-5398c00b1d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoRALayer(nn.Module):\n",
    "    def __init__(self, original_layer: nn.Linear, rank: int, alpha: int, device=None):\n",
    "        super().__init__()\n",
    "        self.original_layer = original_layer\n",
    "        self.lora_update = LoRAUpdate(\n",
    "            in_features=original_layer.in_features,\n",
    "            out_features=original_layer.out_features,\n",
    "            rank=rank,\n",
    "            alpha=alpha,\n",
    "            device=device,\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.original_layer(input) + self.lora_update(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "64589391-bb26-42f6-ba88-936c6fbe7c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MobileBertForSequenceClassification were not initialized from the model checkpoint at google/mobilebert-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "lora_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"google/mobilebert-uncased\",\n",
    "    num_labels=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "908ec246-7e26-488f-964e-b7ad009b31da",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in lora_model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2dce97ad-c2d6-4779-85dd-e90ec768d25e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([param.numel() for param in lora_model.parameters() if param.requires_grad])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8f78f8f9-9bb0-4bd3-8aed-7d53b66b3966",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = 1\n",
    "alpha = 1\n",
    "\n",
    "for layer in lora_model.mobilebert.encoder.layer:\n",
    "    layer.attention.self.query = LoRALayer(\n",
    "        layer.attention.self.query,\n",
    "        rank=rank,\n",
    "        alpha=alpha,\n",
    "    )\n",
    "    layer.attention.self.key = LoRALayer(\n",
    "        layer.attention.self.key,\n",
    "        rank=rank,\n",
    "        alpha=alpha,\n",
    "    )\n",
    "    layer.attention.self.value = LoRALayer(\n",
    "        layer.attention.self.value,\n",
    "        rank=rank,\n",
    "        alpha=alpha,\n",
    "    )\n",
    "    layer.attention.output.dense = LoRALayer(\n",
    "        layer.attention.output.dense,\n",
    "        rank=rank,\n",
    "        alpha=alpha,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e3fd04c9-d3b8-4164-a5e9-e9e1a8a37bae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MobileBertForSequenceClassification(\n",
       "  (mobilebert): MobileBertModel(\n",
       "    (embeddings): MobileBertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 128, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 512)\n",
       "      (token_type_embeddings): Embedding(2, 512)\n",
       "      (embedding_transformation): Linear(in_features=384, out_features=512, bias=True)\n",
       "      (LayerNorm): NoNorm()\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (encoder): MobileBertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-23): 24 x MobileBertLayer(\n",
       "          (attention): MobileBertAttention(\n",
       "            (self): MobileBertSelfAttention(\n",
       "              (query): LoRALayer(\n",
       "                (original_layer): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (lora_update): LoRAUpdate()\n",
       "              )\n",
       "              (key): LoRALayer(\n",
       "                (original_layer): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (lora_update): LoRAUpdate()\n",
       "              )\n",
       "              (value): LoRALayer(\n",
       "                (original_layer): Linear(in_features=512, out_features=128, bias=True)\n",
       "                (lora_update): LoRAUpdate()\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): MobileBertSelfOutput(\n",
       "              (dense): LoRALayer(\n",
       "                (original_layer): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (lora_update): LoRAUpdate()\n",
       "              )\n",
       "              (LayerNorm): NoNorm()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): MobileBertIntermediate(\n",
       "            (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "            (intermediate_act_fn): ReLU()\n",
       "          )\n",
       "          (output): MobileBertOutput(\n",
       "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "            (bottleneck): OutputBottleneck(\n",
       "              (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (LayerNorm): NoNorm()\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (bottleneck): Bottleneck(\n",
       "            (input): BottleneckLayer(\n",
       "              (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (LayerNorm): NoNorm()\n",
       "            )\n",
       "            (attention): BottleneckLayer(\n",
       "              (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (LayerNorm): NoNorm()\n",
       "            )\n",
       "          )\n",
       "          (ffn): ModuleList(\n",
       "            (0-2): 3 x FFNLayer(\n",
       "              (intermediate): MobileBertIntermediate(\n",
       "                (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "                (intermediate_act_fn): ReLU()\n",
       "              )\n",
       "              (output): FFNOutput(\n",
       "                (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "                (LayerNorm): NoNorm()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): MobileBertPooler()\n",
       "  )\n",
       "  (dropout): Dropout(p=0.0, inplace=False)\n",
       "  (classifier): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lora_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c42b2f39-04a7-40bb-80f9-76ec9642bab0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33792"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([param.numel() for param in lora_model.parameters() if param.requires_grad])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdeeac3-5ec0-4611-b62c-a0b6299f1cd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e8e56015-bd1f-491b-997d-3c54a5802b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lora_model = lora_model.to(\"cuda\")\n",
    "lora_model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ae276c-0157-4cba-9812-4e21aadb288d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "86fbe620-53e2-4427-b30f-92b9890d5ae6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21050' max='21050' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21050/21050 41:15, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.268327</td>\n",
       "      <td>0.889908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.239600</td>\n",
       "      <td>0.269902</td>\n",
       "      <td>0.907110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.226000</td>\n",
       "      <td>0.261168</td>\n",
       "      <td>0.907110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.215900</td>\n",
       "      <td>0.267000</td>\n",
       "      <td>0.905963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.213600</td>\n",
       "      <td>0.263096</td>\n",
       "      <td>0.909404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=21050, training_loss=14127.246382535133, metrics={'train_runtime': 2475.9298, 'train_samples_per_second': 136.007, 'train_steps_per_second': 8.502, 'total_flos': 1454588676957348.0, 'train_loss': 14127.246382535133, 'epoch': 5.0})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lora_training_args = TrainingArguments(\n",
    "    output_dir=\"tmp/mobilebert_lora\",\n",
    "    learning_rate=5e-4,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    push_to_hub=False,\n",
    ")\n",
    "\n",
    "lora_trainer = Trainer(\n",
    "    model=lora_model,\n",
    "    args=lora_training_args,\n",
    "    train_dataset=tokenized_sst2[\"train\"],\n",
    "    eval_dataset=tokenized_sst2[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "lora_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e322fdc8-96de-4ceb-9e1f-800421a6ddc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "49b1a3ed-ba04-489b-93d4-6684ea379a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "7808a792-ea50-4956-9b0a-e26182e101a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding_tokenize(batch: Dict[str, List]):\n",
    "    return tokenizer(batch[\"sentence\"], truncation=True, padding=True, max_length=512, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "99f2a32e-6bfd-45a8-9a79-7bb306700342",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_tokenized_sst2 = sst2.map(padding_tokenize, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "dd03917c-9662-4c96-a5f7-a2dc864ecb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(padded_tokenized_sst2[\"validation\"], batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "65a42838-6617-4ec9-95fc-5d63c5e9b094",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_accuracy = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "359bf3b8-53a0-42d5-aee2-7146ccd7a829",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5b606bd0e114add8571237fc9380aa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for batch in tqdm(data_loader):\n",
    "    outputs = lora_model(\n",
    "        input_ids=torch.stack(batch[\"input_ids\"]).T.to(\"cuda\"),\n",
    "        token_type_ids=torch.stack(batch[\"token_type_ids\"]).T.to(\"cuda\"),\n",
    "        attention_mask=torch.stack(batch[\"attention_mask\"]).T.to(\"cuda\"),\n",
    "    )\n",
    "    predictions = outputs.logits.sigmoid().round().detach().cpu().numpy()[:, 1]\n",
    "    labels = batch[\"label\"].numpy()\n",
    "    val_accuracy.add_batch(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "1e580d2f-380a-4987-bfbc-50ae0d437aa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9059633027522935}"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_accuracy.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b85a3a1-8dcc-4ac5-9def-89e5138a210f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00c45af-c439-46ab-8cd2-ba630678d0ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518c9b0b-b35a-4a3e-a9a2-a25bf34d152a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "2129c6ea-32ca-4b67-aef2-941c5dbc397b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MobileBertForSequenceClassification were not initialized from the model checkpoint at google/mobilebert-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "test_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"google/mobilebert-uncased\",\n",
    "    num_labels=2,\n",
    "    output_attentions=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "a9901911-1fcf-4765-89c3-8d880a1d19b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = test_model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "21c8d976-6f15-4046-aa09-02d3fb0ae9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_accuracy = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "7016c4e8-88db-4c77-b17e-496006734a8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "113846ce923d494888f0466ebb41a8e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for batch in tqdm(data_loader):\n",
    "    outputs = test_model(\n",
    "        input_ids=torch.stack(batch[\"input_ids\"]).T.to(\"cuda\"),\n",
    "        token_type_ids=torch.stack(batch[\"token_type_ids\"]).T.to(\"cuda\"),\n",
    "        attention_mask=torch.stack(batch[\"attention_mask\"]).T.to(\"cuda\"),\n",
    "    )\n",
    "    predictions = outputs.logits.sigmoid().round().detach().cpu().numpy()[:, 1]\n",
    "    labels = batch[\"label\"].numpy()\n",
    "    val_accuracy.add_batch(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "de567331-dd73-4f5c-8c20-f86b75c61c51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.5091743119266054}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_accuracy.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "2595029b-2d05-48aa-8ba1-9f6bfb6fd21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "fb599fe4-baac-4059-affe-998f64df1568",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = test_model(\n",
    "    input_ids=torch.stack(batch[\"input_ids\"]).T.to(\"cuda\"),\n",
    "    token_type_ids=torch.stack(batch[\"token_type_ids\"]).T.to(\"cuda\"),\n",
    "    attention_mask=torch.stack(batch[\"attention_mask\"]).T.to(\"cuda\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "504b2b69-f232-499c-9959-71ff1b410999",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(outputs.attentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "f332ad8b-f75c-46de-a8c7-0b1f36cfe420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 4, 55, 55])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.attentions[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "00f486da-80e3-463c-98fe-3e1f78dfd35a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 4, 55, 55])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.attentions[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "1db9efd4-cfa6-492a-843c-03294694429a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 4, 3025])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.attentions[0].flatten(start_dim=-2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702939bb-85ac-40df-aa64-81429abdeca3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
